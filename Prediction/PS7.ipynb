{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102973c9-c2ee-417b-9fc1-cbc65cee7d1c",
   "metadata": {},
   "source": [
    "# Heart Attack Prediction (60pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79113ab6-93a8-4c14-a50a-8653e239af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2363005-c322-4107-a4d7-0342e80edc34",
   "metadata": {},
   "source": [
    "    In this question, we will construct a simple logistic regression model to predict the probability of a person having a heart attack. The dataset comes from Kaggle www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset, which contains health information of each person (predictors) and whether or not the person had a heart attack before (outcome variable). You can download the data heart.csv from Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd9160-bc6d-4d8a-b029-8d4f911be1c9",
   "metadata": {},
   "source": [
    "    1. (2pt) Load the data and drop the variable slp, oldpeak and thall, since they do not have descriptions available. Do some basic sanity check (descriptive statistics; missing values; data types...). The data should contain 303 rows, and 11 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7d478e-c517-4d42-a071-358100c5146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   age       303 non-null    int64\n",
      " 1   sex       303 non-null    int64\n",
      " 2   cp        303 non-null    int64\n",
      " 3   trtbps    303 non-null    int64\n",
      " 4   chol      303 non-null    int64\n",
      " 5   fbs       303 non-null    int64\n",
      " 6   restecg   303 non-null    int64\n",
      " 7   thalachh  303 non-null    int64\n",
      " 8   exng      303 non-null    int64\n",
      " 9   caa       303 non-null    int64\n",
      " 10  output    303 non-null    int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 26.2 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>caa</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  caa  output\n",
       "0   63    1   3     145   233    1        0       150     0    0       1\n",
       "1   37    1   2     130   250    0        1       187     0    0       1\n",
       "2   41    0   1     130   204    0        0       172     0    0       1\n",
       "3   56    1   1     120   236    0        1       178     0    0       1\n",
       "4   57    0   0     120   354    0        1       163     1    0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the heart attack dataframe\n",
    "heart_df = pd.read_csv('/home/jovyan/PS/data/heart.csv', sep=',')\n",
    "# Drop slp, oldpeak and thall columns\n",
    "heart_df.drop(['slp', 'oldpeak', 'thall'], axis = 1, inplace = True)\n",
    "# Sanity Checks\n",
    "heart_df.info()\n",
    "heart_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05fbfb-0fef-442d-b0e0-b06a06f535b5",
   "metadata": {},
   "source": [
    "    2. (22pt) Construct a simple logistic regression with statsmodel.formula.api package. The outcome variable is output. The rest 10 variables (age, sex, cp, trtbps, chol, fbs, restecg, thalachh, exng, caa) in the dataset are predictors. Print out the marginal effect summary table and answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf43808-397f-4334-9773-b6066db3b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.386917\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>output</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>dydx</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>            <td>overall</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <th></th>            <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.1]</th>      <td>    0.2017</td> <td>    0.060</td> <td>    3.353</td> <td> 0.001</td> <td>    0.084</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.2]</th>      <td>    0.2278</td> <td>    0.045</td> <td>    5.084</td> <td> 0.000</td> <td>    0.140</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.3]</th>      <td>    0.2117</td> <td>    0.071</td> <td>    2.977</td> <td> 0.003</td> <td>    0.072</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(restecg)[T.1]</th> <td>    0.0604</td> <td>    0.042</td> <td>    1.452</td> <td> 0.146</td> <td>   -0.021</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(restecg)[T.2]</th> <td>   -0.1007</td> <td>    0.216</td> <td>   -0.467</td> <td> 0.641</td> <td>   -0.523</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>             <td>   -0.0007</td> <td>    0.003</td> <td>   -0.269</td> <td> 0.788</td> <td>   -0.006</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>             <td>   -0.2439</td> <td>    0.047</td> <td>   -5.233</td> <td> 0.000</td> <td>   -0.335</td> <td>   -0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trtbps</th>          <td>   -0.0025</td> <td>    0.001</td> <td>   -2.116</td> <td> 0.034</td> <td>   -0.005</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>            <td>   -0.0008</td> <td>    0.000</td> <td>   -1.866</td> <td> 0.062</td> <td>   -0.002</td> <td> 4.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>             <td>    0.0267</td> <td>    0.059</td> <td>    0.449</td> <td> 0.654</td> <td>   -0.090</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalachh</th>        <td>    0.0039</td> <td>    0.001</td> <td>    3.426</td> <td> 0.001</td> <td>    0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exng</th>            <td>   -0.1354</td> <td>    0.046</td> <td>   -2.943</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa</th>             <td>   -0.0961</td> <td>    0.018</td> <td>   -5.213</td> <td> 0.000</td> <td>   -0.132</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:                 output\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "===================================================================================\n",
       "                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "C(cp)[T.1]          0.2017      0.060      3.353      0.001       0.084       0.320\n",
       "C(cp)[T.2]          0.2278      0.045      5.084      0.000       0.140       0.316\n",
       "C(cp)[T.3]          0.2117      0.071      2.977      0.003       0.072       0.351\n",
       "C(restecg)[T.1]     0.0604      0.042      1.452      0.146      -0.021       0.142\n",
       "C(restecg)[T.2]    -0.1007      0.216     -0.467      0.641      -0.523       0.322\n",
       "age                -0.0007      0.003     -0.269      0.788      -0.006       0.005\n",
       "sex                -0.2439      0.047     -5.233      0.000      -0.335      -0.153\n",
       "trtbps             -0.0025      0.001     -2.116      0.034      -0.005      -0.000\n",
       "chol               -0.0008      0.000     -1.866      0.062      -0.002    4.18e-05\n",
       "fbs                 0.0267      0.059      0.449      0.654      -0.090       0.143\n",
       "thalachh            0.0039      0.001      3.426      0.001       0.002       0.006\n",
       "exng               -0.1354      0.046     -2.943      0.003      -0.226      -0.045\n",
       "caa                -0.0961      0.018     -5.213      0.000      -0.132      -0.060\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the logistic regression and print the marginal effect summary table\n",
    "logit_regression = smf.logit(\"output ~ age + sex + C(cp) + trtbps + chol + fbs + C(restecg) + thalachh + exng + caa\", data = heart_df).fit()\n",
    "logit_regression.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ca7bc-0ef6-4067-9ddb-1b12081cc2d0",
   "metadata": {},
   "source": [
    "In this model, only cp and restecg are seen as categorical variables. Both \"cp\" and \"restecg\" have more than two categories, and these are clearly not interval measures.  So these are inherently categorical, and you should convert those to categories. Sex is categorical. However, it is normally coded as 0/1 (as it did in this dataset), so it does not need to be seen as categorical or make a dummy out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cad682-2a60-4068-ab97-a395ad3cfda9",
   "metadata": {},
   "source": [
    "    (6pt) Interpret coefficient for sex. Is it statistically significant at significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61e423-380c-4652-bcd3-4122b40275f1",
   "metadata": {},
   "source": [
    "Males have 24.39 percentage points less chance to get a heart attack compared to females if the other characters are the same. The coefficient is statistically significant because the p-value is less than the significance level of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2424103-3815-4d86-8a1d-d80f7eb351df",
   "metadata": {},
   "source": [
    "    (6pt) Interpret coefficient for cp. Is it statistically significant at significance level of 0.05?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d24166-a8f7-4b04-a4ba-2a03108403d5",
   "metadata": {},
   "source": [
    "When other characteristics are the same, a patient that has atypical angina chest have 20.17 percentage points more likelihood to get a heart attack, a patient that has non-anginal pain have 22.78 percentage points more likelihood to get a heart attack, a patient that has asymptomatic chest pain have 21.17 percentage points more likelihood to get a heart attack. All these are compared with a patient that has typical angina chest pain. \n",
    "\n",
    "The coefficient is statistically significant as the p-value is less than the significance level of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a1049-21e2-4432-b1c3-9535beb85793",
   "metadata": {},
   "source": [
    "    (6pt) Interpret the coefficient for age. Is it statistically significant at significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ff279-f8b2-4f0c-bc15-9f569da2690d",
   "metadata": {},
   "source": [
    "When other characteristics are the same, with one unit increase in age, the chance of getting heart attacks decreases by 0.07 percentage points. \n",
    "\n",
    "The coefficient is not statistically significant as the p-value is way larger than the significance level of 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2989e-5e93-4503-9b58-cdca09602942",
   "metadata": {},
   "source": [
    "    (4pt) What are the variables that are associated with lower chance of having a heart attack, and also are statistically significant? Do they intuitively make sense? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65796d-fe49-4c1a-a3a6-9a235fca07f3",
   "metadata": {},
   "source": [
    "Variables that are associated with a lower chance of having a heart attack and also statistically significant are resting blood pressure(trtbps), exercise-induced angina(exng), the number of major vessels(caa), and male patients(sex = 1). However, they do not intuitively makes sense because all these variables are associated with a higher chance of having a heart attack based on research and common sense (i.e. having angina increases the chance of getting a heart attack)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f4b56-e898-491e-9d69-4153d53a130d",
   "metadata": {},
   "source": [
    "    (6pt) Now let’s construct the same model with sklearn package using the following code:\n",
    "    LogisticRegression(penalty=’none’, solver=’newton-cg’).fit(X,y)\n",
    "    Remember that sklearn package requires the predictor values (X) to be separated with the outcome variable (y). The predictor values also need to be in matrix format. Answer the following question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e35a0d9-5e77-44c1-b927-d499c9068303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crtaed the predictor values and the outcome variables\n",
    "X1 = heart_df[[\"age\", \"sex\", \"cp\", \"trtbps\", \"chol\", \"fbs\", \"restecg\", \"thalachh\", \"exng\", \"caa\"]]\n",
    "X = pd.get_dummies(X1, drop_first = True, columns = [\"cp\", \"restecg\"]).values\n",
    "y = heart_df[\"output\"].values\n",
    "# Create a logistic regression model with sklearn\n",
    "sklearn_logistic = LogisticRegression(penalty = 'none', solver = 'newton-cg').fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf92f8a-4fc7-4df8-9054-69a94bb11842",
   "metadata": {},
   "source": [
    "    3.(6pt) Print out the coefficient and intercept. Did you get the same intercept and coefficients as what you got from statsmodel.formula.api package? (you are supposed to!!)\n",
    "    (After using both packages, you should have a clearer sense that smf package is good for inferences becuase it provides information about pvalues, tvalues, CI etc., which can be used to determine statistical significance. Sklean package does not provide such information. However, the advantage of sklearn is that it is easier to construct models and make prediction with sklearn, especially when you are comparing multiple models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bfd540-e349-42c4-940f-6daf87e26b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.005895   -1.98329754 -0.02046839 -0.0067561   0.21704038  0.03143576\n",
      "  -1.10053597 -0.78101777  1.63967367  1.8519962   1.72131152  0.49135353\n",
      "  -0.81831285]]\n",
      "Intercept: [1.27592977]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept of the sklearn model\n",
    "print('Coefficients:', sklearn_logistic.coef_)\n",
    "print('Intercept:', sklearn_logistic.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488612b4-499b-46a1-85d2-946cdd75aa86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>output</td>      <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   289</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 17 Mar 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.4386</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:52:45</td>     <th>  Log-Likelihood:    </th> <td> -117.24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -208.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.830e-32</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    1.2759</td> <td>    2.326</td> <td>    0.548</td> <td> 0.583</td> <td>   -3.283</td> <td>    5.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.1]</th>      <td>    1.6397</td> <td>    0.521</td> <td>    3.147</td> <td> 0.002</td> <td>    0.618</td> <td>    2.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.2]</th>      <td>    1.8520</td> <td>    0.417</td> <td>    4.446</td> <td> 0.000</td> <td>    1.036</td> <td>    2.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(cp)[T.3]</th>      <td>    1.7213</td> <td>    0.608</td> <td>    2.833</td> <td> 0.005</td> <td>    0.530</td> <td>    2.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(restecg)[T.1]</th> <td>    0.4914</td> <td>    0.342</td> <td>    1.437</td> <td> 0.151</td> <td>   -0.179</td> <td>    1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(restecg)[T.2]</th> <td>   -0.8183</td> <td>    1.755</td> <td>   -0.466</td> <td> 0.641</td> <td>   -4.258</td> <td>    2.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>             <td>   -0.0059</td> <td>    0.022</td> <td>   -0.269</td> <td> 0.788</td> <td>   -0.049</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>             <td>   -1.9833</td> <td>    0.430</td> <td>   -4.616</td> <td> 0.000</td> <td>   -2.825</td> <td>   -1.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trtbps</th>          <td>   -0.0205</td> <td>    0.010</td> <td>   -2.060</td> <td> 0.039</td> <td>   -0.040</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>            <td>   -0.0068</td> <td>    0.004</td> <td>   -1.840</td> <td> 0.066</td> <td>   -0.014</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>             <td>    0.2170</td> <td>    0.484</td> <td>    0.448</td> <td> 0.654</td> <td>   -0.732</td> <td>    1.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalachh</th>        <td>    0.0314</td> <td>    0.010</td> <td>    3.232</td> <td> 0.001</td> <td>    0.012</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exng</th>            <td>   -1.1005</td> <td>    0.393</td> <td>   -2.802</td> <td> 0.005</td> <td>   -1.870</td> <td>   -0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa</th>             <td>   -0.7810</td> <td>    0.173</td> <td>   -4.525</td> <td> 0.000</td> <td>   -1.119</td> <td>   -0.443</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 output   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      289\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Thu, 17 Mar 2022   Pseudo R-squ.:                  0.4386\n",
       "Time:                        18:52:45   Log-Likelihood:                -117.24\n",
       "converged:                       True   LL-Null:                       -208.82\n",
       "Covariance Type:            nonrobust   LLR p-value:                 3.830e-32\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           1.2759      2.326      0.548      0.583      -3.283       5.835\n",
       "C(cp)[T.1]          1.6397      0.521      3.147      0.002       0.618       2.661\n",
       "C(cp)[T.2]          1.8520      0.417      4.446      0.000       1.036       2.668\n",
       "C(cp)[T.3]          1.7213      0.608      2.833      0.005       0.530       2.912\n",
       "C(restecg)[T.1]     0.4914      0.342      1.437      0.151      -0.179       1.162\n",
       "C(restecg)[T.2]    -0.8183      1.755     -0.466      0.641      -4.258       2.622\n",
       "age                -0.0059      0.022     -0.269      0.788      -0.049       0.037\n",
       "sex                -1.9833      0.430     -4.616      0.000      -2.825      -1.141\n",
       "trtbps             -0.0205      0.010     -2.060      0.039      -0.040      -0.001\n",
       "chol               -0.0068      0.004     -1.840      0.066      -0.014       0.000\n",
       "fbs                 0.2170      0.484      0.448      0.654      -0.732       1.166\n",
       "thalachh            0.0314      0.010      3.232      0.001       0.012       0.050\n",
       "exng               -1.1005      0.393     -2.802      0.005      -1.870      -0.331\n",
       "caa                -0.7810      0.173     -4.525      0.000      -1.119      -0.443\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the summary of the smf logistic regression summary\n",
    "logit_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39c131-ea5e-48df-8d3f-6a1ab92b589b",
   "metadata": {},
   "source": [
    "Although the order is messed up, the logistic regression model from sklearn and from smf do have the same coefficients. The five coefficients of cp and restecg from the smf model corresponds with [1.63967367, 1.8519962, 1.72131152, 0.49135353, -0.81831285]. [-0.005895, -1.98329754, -0.02046839, -0.0067561, 0.21704038, 0.03143576, -1.10053597, -0.78101777] corresponds with the variables age through caa from the smf model. After comparing, the model from sklearn and from smf do have the same coefficients and intercepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1c7c9-45fe-4f86-9c53-985a5bbe5758",
   "metadata": {},
   "source": [
    "    4. (18pt) With the sklearn model, let’s do some predictions on the training set (the same X and y we used to train the model from Q3):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e41c3-76e0-4762-8d08-5c0d648a8e8a",
   "metadata": {},
   "source": [
    "    (6pt) The probability of having a heart attack: P(output=1|X). Print out the first 10 probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dcab0fb-eae8-463e-b82d-f56922ff4ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73747271, 0.95009482, 0.9827361 , 0.93329596, 0.64723174,\n",
       "       0.48443413, 0.92712111, 0.91447984, 0.85496029, 0.92854194])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the probability of having a heart attack\n",
    "heart_atk_prob = sklearn_logistic.predict_proba(X)\n",
    "heart_atk_prob = heart_atk_prob[:, 1]\n",
    "# Print the first 10 probabilities\n",
    "heart_atk_prob[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2dd7cc-acbe-4fdc-b9e5-4ef7ad6bd8fa",
   "metadata": {},
   "source": [
    "    (6pt) The outcome labels — that is, we directly predict whether or not the person will have a heart attack, instead of predicting the probability. Print out the first 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a366f22-b2b4-4494-921e-52dfc04761c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the outcome labels (whether or not a person will have heart attack)\n",
    "heart_atk_label = sklearn_logistic.predict(X)\n",
    "# Print the first 10 labels\n",
    "heart_atk_label[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b64538-3a1f-453e-b762-f070b8ac33c6",
   "metadata": {},
   "source": [
    "    (6pt) Show the steps of how to convert from probabilities to the labels using threshold 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d154eb5-e841-4146-83d5-f64b5172c69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert probabilities to the labels using threshold 0.5\n",
    "prob_label = np.where(heart_atk_prob > 0.5, 1, 0)\n",
    "prob_label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff5712-eb40-4cae-aa01-0efe0a18c3f6",
   "metadata": {},
   "source": [
    "    5. (6pt) Calculate the accuracy of the predicted output labels, compared with the true output labels. You can calculate it using your own code or using sklearn.metrics package. How to interpret the accuracy? Do you think the accuracy is high enough, such that you are comfortable deploying this model in real world to predict heart attack? (Hint: you should get about 80% accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb3827d-a8cb-4a1a-bae4-58c81075d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the predicted output labels: 0.8217821782178217\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score for the predicted output labels\n",
    "accuracy = accuracy_score(y, heart_atk_label)\n",
    "print('Accuracy of the predicted output labels:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8d599-fbd8-43f8-9738-f862d8623f2c",
   "metadata": {},
   "source": [
    "This is interpreted as the accuracy for predicting if someone will have a heart attack or not is around 80% accurate using the model. I think the accuracy is high enough because having a heart attack is already difficult enough to predict since so many different factors can cause it. Therefore, I would be mostly comfortable deploying this model to predict heart attacks in real life. However, it is also to keep in mind that the model's predictions will not be perfect. People need to monitor and double-check before telling the patients that they will not have a heart attack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e95c1-74d1-4d61-9199-81175a94e45b",
   "metadata": {},
   "source": [
    "    6. (6pt) Create a confusion matrix on the training data. Calculate accuracy, precision, and recall based on the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a9bf0d-5bee-492d-bb9a-22ccfac44259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[106,  32],\n",
       "       [ 22, 143]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confusion matrix on the training data\n",
    "cm = confusion_matrix(y, heart_atk_label)\n",
    "print('Confusion Matrix:')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4762bd6c-d500-4547-a472-a93792c40eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8217821782178217\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy_cm = accuracy_score(y, heart_atk_label)\n",
    "print('Accuracy:', accuracy_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f6aeca-6c0d-4bc2-a421-9614d460c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8171428571428572\n"
     ]
    }
   ],
   "source": [
    "# Compute the precision\n",
    "precision = precision_score(y, heart_atk_label)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573f68b9-4774-44da-8d66-225190215eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# COmpute the recall\n",
    "recall = recall_score(y, heart_atk_label)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee6acd-9c49-4f29-a1a0-da2dc8ddf7bf",
   "metadata": {},
   "source": [
    "# Predict AirBnB Price (40pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbdf09d-b528-4e43-aba4-f1d4b24c288f",
   "metadata": {},
   "source": [
    "    Your second task is to predict Beijing AirBnB listing price (variable price). You use the same dataset as in PS06, and the same model (model in question 2.7).    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dafd7e-6c97-4462-8709-e464b06d7f7a",
   "metadata": {},
   "source": [
    "    1. (5pt) Replicate the model from PS06 question 2.7. Copy paste of your old code is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4c6f93-78d6-424c-9ed6-cb8cb3721fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the airbnb data\n",
    "airbnb_df = pd.read_csv('/home/jovyan/PS/data/airbnb-beijing-listings.csv', sep = \",\", usecols = [\"accommodates\", \"price\", \"room_type\", \"bedrooms\", \"bathrooms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dcbccc1-469f-46ec-9bf0-d76543a4a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert price to numeric\n",
    "airbnb_df['price'] = airbnb_df['price'].apply(lambda x: x.replace('$', ''))\n",
    "airbnb_df['price'] = airbnb_df['price'].apply(lambda x: x.replace(',', ''))\n",
    "airbnb_df['price'] = pd.to_numeric(airbnb_df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d05166-91e6-451d-9ba2-84eb5b4666fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type       0\n",
       "accommodates    0\n",
       "bathrooms       0\n",
       "bedrooms        0\n",
       "price           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the entries with missing or invalid price, bedrooms or other variables\n",
    "airbnb_df.dropna(inplace = True)\n",
    "# 0 cannot exsists when doing log transformations, remove prices that are 0 and also price should not be 0\n",
    "airbnb_df = airbnb_df[airbnb_df.price != 0]\n",
    "airbnb_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff06eb18-6dda-47cc-bc41-c9de01411900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another variable called bedroom_category that is based on the number of bedrooms\n",
    "airbnb_df['bedroom_category'] = pd.cut(airbnb_df.bedrooms,\n",
    "                                       bins = [-np.inf, 0, 1, 2, 3, np.inf],\n",
    "                                       labels = [\"0\", \"1\", \"2\", \"3\", \"4+\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2c152e-d778-407e-9d02-f5831e7a299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.457</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.457</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2709.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 17 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:52:50</td>     <th>  Log-Likelihood:    </th> <td> -35751.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 38686</td>      <th>  AIC:               </th> <td>7.153e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 38673</td>      <th>  BIC:               </th> <td>7.164e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>    5.5770</td> <td>    0.062</td> <td>   90.051</td> <td> 0.000</td> <td>    5.456</td> <td>    5.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedroom_category)[T.1]</th>               <td>    0.0558</td> <td>    0.040</td> <td>    1.395</td> <td> 0.163</td> <td>   -0.023</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedroom_category)[T.2]</th>               <td>    0.1898</td> <td>    0.041</td> <td>    4.632</td> <td> 0.000</td> <td>    0.110</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedroom_category)[T.3]</th>               <td>    0.4926</td> <td>    0.042</td> <td>   11.633</td> <td> 0.000</td> <td>    0.410</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bedroom_category)[T.4+]</th>              <td>    0.8730</td> <td>    0.044</td> <td>   19.909</td> <td> 0.000</td> <td>    0.787</td> <td>    0.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(room_type)[T.Private room]</th>           <td>   -0.3243</td> <td>    0.007</td> <td>  -43.838</td> <td> 0.000</td> <td>   -0.339</td> <td>   -0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(room_type)[T.Shared room]</th>            <td>   -0.9453</td> <td>    0.017</td> <td>  -56.064</td> <td> 0.000</td> <td>   -0.978</td> <td>   -0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(accommodates_category)[T.2]</th>          <td>    0.3298</td> <td>    0.013</td> <td>   24.452</td> <td> 0.000</td> <td>    0.303</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(accommodates_category)[T.3]</th>          <td>    0.3921</td> <td>    0.017</td> <td>   23.543</td> <td> 0.000</td> <td>    0.359</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(accommodates_category)[T.4 and more]</th> <td>    0.6066</td> <td>    0.015</td> <td>   39.175</td> <td> 0.000</td> <td>    0.576</td> <td>    0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bathrooms_category)[T.1]</th>             <td>    0.0049</td> <td>    0.047</td> <td>    0.106</td> <td> 0.916</td> <td>   -0.087</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bathrooms_category)[T.2]</th>             <td>    0.0386</td> <td>    0.047</td> <td>    0.819</td> <td> 0.413</td> <td>   -0.054</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(bathrooms_category)[T.3 and more]</th>    <td>    0.5938</td> <td>    0.049</td> <td>   12.017</td> <td> 0.000</td> <td>    0.497</td> <td>    0.691</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>9116.538</td> <th>  Durbin-Watson:     </th> <td>   1.779</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>54083.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.003</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.434</td>  <th>  Cond. No.          </th> <td>    52.9</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              log_price   R-squared:                       0.457\n",
       "Model:                            OLS   Adj. R-squared:                  0.457\n",
       "Method:                 Least Squares   F-statistic:                     2709.\n",
       "Date:                Thu, 17 Mar 2022   Prob (F-statistic):               0.00\n",
       "Time:                        18:52:50   Log-Likelihood:                -35751.\n",
       "No. Observations:               38686   AIC:                         7.153e+04\n",
       "Df Residuals:                   38673   BIC:                         7.164e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                  5.5770      0.062     90.051      0.000       5.456       5.698\n",
       "C(bedroom_category)[T.1]                   0.0558      0.040      1.395      0.163      -0.023       0.134\n",
       "C(bedroom_category)[T.2]                   0.1898      0.041      4.632      0.000       0.110       0.270\n",
       "C(bedroom_category)[T.3]                   0.4926      0.042     11.633      0.000       0.410       0.576\n",
       "C(bedroom_category)[T.4+]                  0.8730      0.044     19.909      0.000       0.787       0.959\n",
       "C(room_type)[T.Private room]              -0.3243      0.007    -43.838      0.000      -0.339      -0.310\n",
       "C(room_type)[T.Shared room]               -0.9453      0.017    -56.064      0.000      -0.978      -0.912\n",
       "C(accommodates_category)[T.2]              0.3298      0.013     24.452      0.000       0.303       0.356\n",
       "C(accommodates_category)[T.3]              0.3921      0.017     23.543      0.000       0.359       0.425\n",
       "C(accommodates_category)[T.4 and more]     0.6066      0.015     39.175      0.000       0.576       0.637\n",
       "C(bathrooms_category)[T.1]                 0.0049      0.047      0.106      0.916      -0.087       0.097\n",
       "C(bathrooms_category)[T.2]                 0.0386      0.047      0.819      0.413      -0.054       0.131\n",
       "C(bathrooms_category)[T.3 and more]        0.5938      0.049     12.017      0.000       0.497       0.691\n",
       "==============================================================================\n",
       "Omnibus:                     9116.538   Durbin-Watson:                   1.779\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            54083.795\n",
       "Skew:                           1.003   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.434   Cond. No.                         52.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new variable accommodates_category that contains the recoded accommodates\n",
    "airbnb_df['accommodates_category'] = pd.cut(airbnb_df.accommodates,\n",
    "                                            bins = [-np.inf, 1, 2, 3, np.inf],\n",
    "                                            labels = [\"1\", \"2\", \"3\", \"4 and more\"])\n",
    "\n",
    "# Create a new variable bathrooms_category that contains the recoded bathrooms\n",
    "airbnb_df['bathrooms_category'] = pd.cut(airbnb_df.bathrooms,\n",
    "                                         bins = [-np.inf, 0, 1, 2, np.inf],\n",
    "                                         labels = [\"0\", \"1\", \"2\", \"3 and more\"])\n",
    "# Create log price\n",
    "log_price = np.log(airbnb_df.price)\n",
    "# Create a new linear regression model with added variables\n",
    "bed_bath_acc_regression = smf.ols(\"log_price ~ C(bedroom_category) + C(room_type) + C(accommodates_category) + C(bathrooms_category)\", data = airbnb_df).fit()\n",
    "bed_bath_acc_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9b5a4-0c2f-4ccd-bc4a-7c2b52ebee27",
   "metadata": {},
   "source": [
    "    2. (10pt) Now use the model above to predict (log) price for each listing in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7274cb63-cc8c-42db-9f87-ba271feb1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions:\n",
      "0    6.714846\n",
      "1    5.643265\n",
      "2    5.967600\n",
      "3    5.967600\n",
      "4    5.967600\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use the model above to predict log price for each listing in data\n",
    "y_hat = bed_bath_acc_regression.predict(airbnb_df)\n",
    "print('First 5 predictions:')\n",
    "print(y_hat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843750df-a50c-4259-ac57-d56a7748b2bb",
   "metadata": {},
   "source": [
    "    3. (10pt) Compute root-mean-squared-error (RMSE) of this prediction. RMSE is explained in lecture notes, 4.1.5 “Model evaluation: MSE, RMSE, R2”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "438e342e-b2b6-400d-84d9-52e1cdd6c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-Mean-Squared-Error: 0.6096875134569459\n"
     ]
    }
   ],
   "source": [
    "# Compute the root-mean-sqaured-error of the prediction\n",
    "rmse = mean_squared_error(log_price, y_hat) ** 0.5\n",
    "print('Root-Mean-Squared-Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb9674-fe41-4028-bd93-57b5ce6be9f4",
   "metadata": {},
   "source": [
    "    4. (10pt) Now use your model to predict the price for a 2-bedroom apartment that accommodates (i.e. a full 2BR apartment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "421b9691-0e6c-43fd-b1e0-40aa39e26ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.412053\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a test to predict price with \n",
    "test = pd.DataFrame({\"bedroom_category\":[\"2\"], \"room_type\":[\"Entire home/apt\"], \"accommodates_category\":[\"4 and more\"], \"bathrooms_category\":[\"2\"]})\n",
    "# Predict the log price\n",
    "bed_bath_acc_regression.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce217c-34cc-4102-9ac8-f0bb0e8e398a",
   "metadata": {},
   "source": [
    "In the prediction for the log price, several assumptions are made. First, it is assumed that there are 2 corresponding bathrooms since there are 2 bedrooms. Second, since the question says \"a 2-bedroom apartment\", the room type is assumed to be entire home/apt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63afba-3171-46b5-82ef-fb56204e66e6",
   "metadata": {},
   "source": [
    "    5. (5pt) Compute the average log price for all listings in this group (2BR apartment that accommodates 4). Compare the result with your prediction. How close did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b17f8d41-f16a-409d-9106-e06f1f21b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.509954544084154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find other matching conditions in the original dataframe\n",
    "match = airbnb_df[(airbnb_df.bedroom_category == '2') & (airbnb_df.room_type == 'Entire home/apt') & (airbnb_df.accommodates_category == '4 and more') & (airbnb_df.bathrooms_category == '2')]\n",
    "# Compute the average log price for all listings in the group\n",
    "np.mean(np.log(match.price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355d395-f1ce-4e20-9f3f-ea6826026651",
   "metadata": {},
   "source": [
    "After comparing the result with my prediction, the results are very similar. My prediction predictes that an airbnb with the conditions has a log price of 6.412053 and the averge log price for all listings with the same conditions is about 6.509955. The difference is about 0.098 which is fairly small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
